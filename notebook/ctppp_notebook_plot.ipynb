{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the CT PPP data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries. To avoid truncating the number of rows displayed in output, the max_rows below can be set to 'None'. Because output can be over 60K rows, this limit is useful to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotnine as p9\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = \"{:,.0f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the three JSON files that contain the CT PPP data. Unless the JSON files are in the same working directory as this notebook when working locally on your computer, it will necessary to use full path names for the files. <br><br>If using Google Colab, first upload these JSON files to Colab by clicking the folder icon at the notebook's sidebar and then clicking the upload button. Then preface the JSON filenames below with '/content/', so that the first filename below is '/content/ctppp_small_063020.json' instead. <br><br>Here we assign <\\\\$150K loans to the small_df dataframe, the >\\\\$150K loans to the large_df dataframe, and the composite dataset to the total_df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = pd.read_json('ctppp_small_063020.json', dtype={'Zip': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df = pd.read_json('ctppp_large_063020.json', dtype={'Zip': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_json('ctppp_total_063020.json', dtype={'Zip': 'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple approach for creating point estimates of the >\\\\$150K loans is to assign the same dollar value for all loans in the same dollar range. E.g., \\\\$7.5M for all \\\\$5M-10M loans. This is not an actual estimate per se, but a standardization of the larger loan values. For the sake of simplicity, this approach is used below to illustrate aggregrate loan dollar amounts. This standardization uses the following steps:\n",
    "1. Use the reported SBA total loan dollar amount for CT and subtract out deleted loans from this SBA total. In subtracting out the deleted loans, for <\\\\$150K loans, use the actual loan amount reported; for >\\\\$150K loans, use the midpoint of the dollar range for that loan. E.g., \\\\$250K for \\\\$150K-\\\\$350K loans.\n",
    "2. Compute a percentage of the dollar range that will be added to the loan mininum to give the standardized loan value. Use the same percentage for all loan ranges. E.g., 50% would yield the midpoint for all the loan ranges. In the initial tranche of data provided by the SBA, 35.425% was deemed appropriate after cleaning the data and subtracting out deleted items.\n",
    "3. Follow this approach to create another standardized column of loan amounts in the large and total loan dataframes. Actual reported loan amounts for the <\\\\$150K loans are still always used in this new column, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization_percentage = 0.35425\n",
    "large_df['StandardLoanAmount'] = (large_df['LoanMin']+(large_df['LoanMax']-large_df['LoanMin'])*standardization_percentage)\n",
    "total_df['StandardLoanAmount'] = (total_df['LoanMin']+(total_df['LoanMax']-total_df['LoanMin'])*standardization_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these standardized loan amounts, it is easier to illustrate aggregate relationships in the data. The CT PPP data is now fully available in the notebook for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example generates a dotplot of retained jobs for each of the loan ranges >\\\\$150K. First confirm the number of borrowers that did not give information on retained jobs and the number that answered 'zero' retained jobs. Then create the dotplot using the plotnine (Grammar of Graphics) library and save it to the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(large_df['JobsRetained'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(large_df['JobsRetained']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "p = (\n",
    "    p9.ggplot(large_df)\n",
    "    + p9.geom_point(p9.aes(x='LoanRange',y='JobsRetained'), position='jitter', alpha=0.5)\n",
    "    + p9.labs(y='Self-Reported Jobs Retained', x='', title='Larger loans reported higher job retention')\n",
    "    + p9.theme(axis_text_x=None, figure_size=(9,6))\n",
    "    + p9.theme(plot_title=p9.element_text(size=18, face='bold'))\n",
    "    + p9.coord_flip()\n",
    ")\n",
    "p.save(filename='large_loan_jobs.png', width=9, height=6, units='in', dpi=600)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example is a simple truncated histogram of the reported jobs retained among the <\\\\$150 loans. In this case, the distribution is cut off at 25 jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(small_df['JobsRetained'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(small_df['JobsRetained']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df['JobsRetained'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    p9.ggplot(small_df[(small_df['JobsRetained']<=25)])\n",
    "    + p9.geom_bar(p9.aes(x='JobsRetained'), size=1.0, fill='cornflowerblue')\n",
    "    + p9.labs(x='Reported Jobs Retained', y='Loan Count', title='Smaller loans averaged 5 jobs retained')\n",
    "    + p9.theme(figure_size=(9,6))\n",
    "    + p9.theme(plot_title=p9.element_text(size=18, face='bold'))\n",
    ")\n",
    "p.save(filename='small_loan_jobs.png', width=9, height=6, units='in', dpi=600)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last example shows the total loan dollar volume approved each day, for the three largest and three smallest loan ranges. In order to more easily work with dates, transform the current date column, 'DateApproved', in the dataframe into a new datetime-aware column, 'DateTime', and save it in the total_df dataframe. Use this column in the plot. Find the largest daily total loan dollar amount to label the axis manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['DateTime'] = pd.to_datetime(total_df['DateApproved'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.groupby(['DateTime','LoanRange'])['StandardLoanAmount'].sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date_format below is used to customize the date labels: it's not mandatory and this next line can be eliminated, along with the full line of code associated with the date_format in the plot code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mizani.formatters import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    p9.ggplot(total_df[(total_df.LoanRange!='d $350,000-1 million') &\n",
    "                              (total_df.LoanRange!='e $150,000-350,000')])\n",
    "    + p9.geom_col(p9.aes(x='DateTime',y='StandardLoanAmount'), color='cornflowerblue')\n",
    "    + p9.labs(x='Loan Approval Date', y='', title='Larger loans were approved earlier')\n",
    "    + p9.theme(axis_text_x=p9.element_text(angle=30))\n",
    "    + p9.scale_x_datetime(labels=date_format('%-m-%-d'))\n",
    "    + p9.theme(axis_text_x=None, figure_size=(9,6))\n",
    "    + p9.theme(plot_title=p9.element_text(size=18, face='bold'))\n",
    "    + p9.scale_y_continuous(labels=['0','50mm', '100mm','150mm'])\n",
    "    + p9.facet_wrap('~ LoanRange', ncol=3)\n",
    ")\n",
    "p.save(filename='approvals_loan_range.png', width=9, height=6, units='in', dpi=600)\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
